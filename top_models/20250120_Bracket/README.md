# Bracket.sh
Bracket is built on a breakthrough with which we build intermediate representation of codebases, allowing LLMs to work at higher levels of layered abstractions rather than raw code.
You can find us at [Bracket.sh](http://bracket.sh/)
Point of contact:
- Dhruv Rathi (dhruv@bracket.sh)

## SWE-Bench Results
Total instances 500
Resolved: 266
Rate of resolution: 53.2%

## Approach
Bracket's differentiator is how accurately and fast it understands very large codebases. As a result, accuray of Fault Localization becomes very high. 
After locating the fault sources, specialized agents handle each step of fixing it. This vertical “scaffolding” adapts to the complexity of both the problem and the code, producing solid results with minimal overhead.

## Result Notes
	•	Model: gpt-4o-mini
	•	Average Cost per Task: $0.60
	•	Average Time per Task: ~5 minutes 20 seconds (with parallelized agent work)
	•	Budget Context: Single-founder setup using a cost-friendly model, expecting better outcomes with upgraded models in future.
	•	Submission Flow: Solutions pass an initial check, run in a sandbox, and get final validation by a “judge” agent. Therefore, adheres to pass@1 ruling.


## Checklist

[✅] Is a pass@1 submission (does not attempt the same task instance more than once)

[✅] Does not use SWE-bench test knowledge (PASS_TO_PASS, FAIL_TO_PASS)

[✅] Does not use the hints field in SWE-bench

[✅] Does not have web-browsing OR has taken steps to prevent lookup of SWE-bench solutions via web-browsing